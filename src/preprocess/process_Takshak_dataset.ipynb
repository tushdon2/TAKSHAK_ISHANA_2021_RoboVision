{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import json\r\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting different image file names"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Location of the directory containing the dataset images and the json files\r\n",
    "datasetDir = \"../../assets/Takshak_dataset40%\" \r\n",
    "filenames = os.listdir(datasetDir)\r\n",
    "imagenames = []\r\n",
    "for file in filenames:\r\n",
    "    if file.split('.')[-1] == 'png':\r\n",
    "        imagenames.append(file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Directories where the processed images and json files will be stored\r\n",
    "imgSaveDir = \"../../assets/Preprocessed_Takshak_dataset/img\"\r\n",
    "jsonSaveDir = \"../../assets/Preprocessed_Takshak_dataset/json\"\r\n",
    "if not os.path.exists(imgSaveDir): os.makedirs(imgSaveDir)\r\n",
    "if not os.path.exists(jsonSaveDir): os.makedirs(jsonSaveDir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "for name in imagenames:\r\n",
    "    img = Image.open(os.path.join(datasetDir, name)) # read the image\r\n",
    "    width, height = img.size\r\n",
    "\r\n",
    "    jsonName = name.split('.')[0] + \".json\"\r\n",
    "    f = open(os.path.join(datasetDir, jsonName)) # opened the json file\r\n",
    "    coordinates = json.load(f) # read the data\r\n",
    "    f.close() # closed the file\r\n",
    "\r\n",
    "    # Training dataset images are 1500 x 1500 in size\r\n",
    "\r\n",
    "    # Manipulate width\r\n",
    "    newWid = 1500 \r\n",
    "    if width <= 1500 or (coordinates['Start'][0] < 1500 and coordinates['End'][0] < 1500):\r\n",
    "        left = 0\r\n",
    "    elif (coordinates['Start'][0] - coordinates['End'][0]) < 1500:\r\n",
    "        left = (coordinates['Start'][0] + coordinates['End'][0]) // 2 - 749\r\n",
    "    # else if (coordinates['Start'][0] - coordinates['End'][0]) >= 1500: we are doomed\r\n",
    "\r\n",
    "    # Manipulate height\r\n",
    "    newHig = 1500\r\n",
    "    if height <= 1500 or (coordinates['Start'][1] < 1500 and coordinates['End'][1] < 1500): top = 0\r\n",
    "    elif (coordinates['Start'][1] - coordinates['End'][1]) < 1500:\r\n",
    "        top = (coordinates['Start'][1] + coordinates['End'][1]) // 2 - 749\r\n",
    "    # else if (coordinates['Start'][1] - coordinates['End'][1]) >= 1500: we are doomed\r\n",
    "\r\n",
    "    # Crop/extend the image\r\n",
    "    img1 = img.crop((left, top, left + newWid, top + newHig))\r\n",
    "\r\n",
    "    # convert transparent pixels to white\r\n",
    "    pixData = img1.getdata()\r\n",
    "    newData = []\r\n",
    "    for item in pixData:\r\n",
    "        if item[3] == 0: item = (255, 255, 255, 255)\r\n",
    "        newData.append(item)\r\n",
    "    img1.putdata(newData)\r\n",
    "    img1.convert(\"RGB\")\r\n",
    "\r\n",
    "    img1.save(os.path.join(imgSaveDir, name)) # save the image\r\n",
    "\r\n",
    "    # Creating a json file and writing coordinate shifts in it \r\n",
    "    jsonData = {}\r\n",
    "    jsonData[\"Shift\"] = (left, top)\r\n",
    "    jsonObj = json.dumps(jsonData, indent = 4)\r\n",
    "    f = open(os.path.join(jsonSaveDir, jsonName), 'w')\r\n",
    "    f.write(jsonObj)\r\n",
    "    f.close() \r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "59e2289ca57af2abdb2de8161cabdb63ec4fa8509fdbe76da7ad981afd55bcdc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}